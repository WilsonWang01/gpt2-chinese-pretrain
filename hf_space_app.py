# HuggingFace Space: app.py
# ================================
# éƒ¨ç½²æ­¥éª¤:
# 1. åœ¨ huggingface.co/spaces åˆ›å»ºæ–° Space
# 2. SDK é€‰æ‹© Gradio, Hardware é€‰æ‹© CPU basic
# 3. ä¸Šä¼ æ­¤æ–‡ä»¶å’Œ requirements.txt
# ================================

import gradio as gr
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# ============================================
MODEL_ID = "Wilsonwin/gpt2-chinese-mini"
# ============================================

print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_ID}")

try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
    model = AutoModelForCausalLM.from_pretrained(MODEL_ID)
    model.eval()
    LOAD_SUCCESS = True
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    tokenizer = None
    model = None
    LOAD_SUCCESS = False


def generate_text(
    prompt: str,
    max_length: int = 150,
    temperature: float = 0.8,
    top_k: int = 50,
    top_p: float = 0.95,
) -> str:
    """ç”Ÿæˆä¸­æ–‡æ–‡æœ¬"""
    
    if not LOAD_SUCCESS:
        return "âŒ æ¨¡å‹æœªåŠ è½½æˆåŠŸï¼Œè¯·æ£€æŸ¥æ¨¡å‹ ID æ˜¯å¦æ­£ç¡®"
    
    if not prompt or not prompt.strip():
        return "è¯·è¾“å…¥æç¤ºæ–‡æœ¬"
    
    prompt = prompt.strip()
    
    try:
        inputs = tokenizer(prompt, return_tensors="pt")
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=min(max_length, 300),
                temperature=max(temperature, 0.1),
                top_k=top_k,
                top_p=top_p,
                do_sample=True,
                pad_token_id=tokenizer.pad_token_id,
                eos_token_id=tokenizer.eos_token_id,
                no_repeat_ngram_size=2,
                repetition_penalty=1.1,
            )
        
        generated = tokenizer.decode(outputs[0], skip_special_tokens=True)
        return generated
    
    except Exception as e:
        return f"ç”Ÿæˆå‡ºé”™: {str(e)}"


# === CSS æ ·å¼ ===
custom_css = """
.gradio-container {
    max-width: 900px !important;
}
.output-text {
    font-size: 16px;
    line-height: 1.8;
}
"""

# === Gradio ç•Œé¢ ===
with gr.Blocks(
    title="ä¸­æ–‡ GPT-2 Mini",
    theme=gr.themes.Soft(),
    css=custom_css
) as demo:
    
    gr.Markdown("""
    # ğŸ‡¨ğŸ‡³ ä¸­æ–‡ GPT-2 Mini - ä»é›¶é¢„è®­ç»ƒæ¼”ç¤º
    
    è¿™æ˜¯ä¸€ä¸ªåœ¨ **A100 GPU** ä¸Šä»éšæœºæƒé‡å¼€å§‹è®­ç»ƒçš„ä¸­æ–‡è¯­è¨€æ¨¡å‹ã€‚
    
    ### ğŸ“Š æ¨¡å‹ä¿¡æ¯
    | å±æ€§ | å€¼ |
    |---|---|
    | æ¶æ„ | GPT-2 (8 å±‚, 768 ç»´) |
    | å‚æ•°é‡ | 82M |
    | è®­ç»ƒæ•°æ® | ä¸­æ–‡ç»´åŸºç™¾ç§‘ + çŸ¥ä¹é—®ç­” |
    | è¯è¡¨å¤§å° | 32,000 (SentencePiece) |
    | è®­ç»ƒæ—¶é•¿ | ~1.4 å°æ—¶ (11,838 æ­¥) |
    
    > âš ï¸ **æ³¨æ„**: è¿™æ˜¯ä¸€ä¸ªæ•™å­¦æ¼”ç¤ºæ¨¡å‹ï¼Œç”Ÿæˆè´¨é‡æœ‰é™ï¼Œå¯èƒ½äº§ç”Ÿä¸å‡†ç¡®æˆ–æ— æ„ä¹‰çš„å†…å®¹ã€‚
    """)
    
    with gr.Row():
        with gr.Column(scale=2):
            prompt_input = gr.Textbox(
                label="ğŸ“ è¾“å…¥æç¤ºè¯",
                placeholder="ä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•...",
                lines=3,
                max_lines=5,
            )
            
            with gr.Accordion("âš™ï¸ ç”Ÿæˆå‚æ•°", open=False):
                max_length = gr.Slider(
                    minimum=50, maximum=300, value=150, step=10,
                    label="æœ€å¤§é•¿åº¦",
                    info="ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§ token æ•°"
                )
                temperature = gr.Slider(
                    minimum=0.1, maximum=1.5, value=0.8, step=0.1,
                    label="æ¸©åº¦ (Temperature)",
                    info="è¶Šé«˜è¶Šéšæœºï¼Œè¶Šä½è¶Šç¡®å®š"
                )
                top_k = gr.Slider(
                    minimum=10, maximum=100, value=50, step=5,
                    label="Top-K",
                    info="ä»æ¦‚ç‡æœ€é«˜çš„ K ä¸ª token ä¸­é‡‡æ ·"
                )
                top_p = gr.Slider(
                    minimum=0.5, maximum=1.0, value=0.95, step=0.05,
                    label="Top-P (Nucleus)",
                    info="ä»ç´¯ç§¯æ¦‚ç‡è¾¾åˆ° P çš„ token ä¸­é‡‡æ ·"
                )
            
            generate_btn = gr.Button("ğŸš€ ç”Ÿæˆæ–‡æœ¬", variant="primary", size="lg")
        
        with gr.Column(scale=3):
            output = gr.Textbox(
                label="ğŸ“– ç”Ÿæˆç»“æœ",
                lines=10,
                max_lines=15,
                show_copy_button=True,
                elem_classes=["output-text"],
            )
    
    # ç»‘å®šäº‹ä»¶
    generate_btn.click(
        fn=generate_text,
        inputs=[prompt_input, max_length, temperature, top_k, top_p],
        outputs=output,
    )
    
    prompt_input.submit(
        fn=generate_text,
        inputs=[prompt_input, max_length, temperature, top_k, top_p],
        outputs=output,
    )
    
    # ç¤ºä¾‹
    gr.Examples(
        examples=[
            ["ä¸­å›½çš„å†å²å¯ä»¥è¿½æº¯åˆ°"],
            ["äººå·¥æ™ºèƒ½æ˜¯ä¸€ç§"],
            ["åœ¨ç§‘å­¦ç ”ç©¶ä¸­ï¼Œ"],
            ["æ•™è‚²çš„é‡è¦æ€§åœ¨äº"],
            ["æœªæ¥çš„åŸå¸‚å°†ä¼š"],
        ],
        inputs=prompt_input,
        label="ğŸ’¡ ç¤ºä¾‹æç¤ºè¯"
    )
    
    gr.Markdown("""
    ---
    ### ğŸ”— ç›¸å…³é“¾æ¥
    - [æ¨¡å‹ä»“åº“](https://huggingface.co/Wilsonwin/gpt2-chinese-mini) - ä¸‹è½½æ¨¡å‹æƒé‡
    - [è®­ç»ƒæ•°æ®](https://huggingface.co/datasets/Wilsonwin/chinese-wiki-zhihu-corpus) - 7.56M æ¡ä¸­æ–‡è¯­æ–™
    
    ### ğŸ“š æŠ€æœ¯ç»†èŠ‚
    - **åˆ†è¯å™¨**: SentencePiece Unigram (32K è¯è¡¨ï¼Œä¸“ä¸ºä¸­æ–‡ä¼˜åŒ–)
    - **è®­ç»ƒæ¡†æ¶**: Hugging Face Transformers + Flash Attention 2 + 8-bit AdamW
    - **è®­ç»ƒç¡¬ä»¶**: AutoDL A100 40GB
    """)


# å¯åŠ¨
if __name__ == "__main__":
    demo.launch()
